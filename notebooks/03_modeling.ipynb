{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Project 4 : Comparing 3 Models for Predicting Recidivism\n",
    "\n",
    "For background on this project, please see the [README](../README.md).\n",
    "\n",
    "**Notebooks**\n",
    "- [Data Acquisition & Cleaning](./01_data_acq_clean.ipynb)\n",
    "- [Exploratory Data Analysis](./02_eda.ipynb)\n",
    "- Modeling (this notebook)\n",
    "- [Results and Recommendations](./04_results.ipynb)\n",
    "\n",
    "**In this notebook, you'll find:**\n",
    "- Classification models for each of the 3 datasets\n",
    "- TODO etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 1: Base feature set - New York**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import plot_confusion_matrix, confusion_matrix\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import utils\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r ny_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define X and y, Train Test and Split the Data\n",
    "\n",
    "X = ny_df[['gender_map', 'Age at Release']]\n",
    "y = ny_df['recidivism']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, stratify = y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Basic Models- Two Features Gender and Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression, Instantiate and Fit Model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "#Save train and test accuracy for model evaluation\n",
    "log_train = lr.score(X_train, y_train)\n",
    "log_test = lr.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest, Instantiate and Fit\n",
    "rf= RandomForestClassifier(random_state = 42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "#Save train and test accuracy for model eval\n",
    "rf_train = rf.score(X_train, y_train)\n",
    "rf_test = rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boost\n",
    "ada= AdaBoostClassifier(base_estimator = DecisionTreeClassifier(random_state = 42))\n",
    "ada.fit(X_train, y_train)\n",
    "\n",
    "ada_train = ada.score(X_train, y_train)\n",
    "ada_test = ada.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gradient Boost\n",
    "gboost= GradientBoostingClassifier(random_state = 42)\n",
    "gboost.fit(X_train, y_train)\n",
    "\n",
    "gb_train = gboost.score(X_train, y_train)\n",
    "gb_test = gboost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Model\n",
    "level1_estimators = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('gboost', GradientBoostingClassifier()),\n",
    "    ('ada', AdaBoostClassifier())\n",
    "]\n",
    "\n",
    "stacked_model = StackingClassifier(estimators=level1_estimators,\n",
    "                                 final_estimator = LogisticRegression())\n",
    "\n",
    "stacked_model.fit(X_train, y_train)\n",
    "\n",
    "#Save train and test accuracy for model eval\n",
    "stack_train = stacked_model.score(X_train, y_train)\n",
    "stack_test = stacked_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "ss = StandardScaler()\n",
    "X_train_sc=ss.fit_transform(X_train)\n",
    "X_test_sc= ss.transform(X_test)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "#Save train and test accuracy for model eval\n",
    "knn_train = knn.score(X_train, y_train)\n",
    "knn_test = knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Models Including County, Gender, Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Dataframe including dummies of the county of indictment\n",
    "df_dummies = pd.get_dummies(ny_df['County of Indictment'])\n",
    "df_dummies['gender'] = ny_df['gender_map']\n",
    "df_dummies['recidivism'] = ny_df['recidivism']\n",
    "df_dummies['age'] = ny_df['Age at Release']\n",
    "\n",
    "#Define X and y with dummy data\n",
    "X = df_dummies.drop(columns = ['recidivism'])\n",
    "y = df_dummies['recidivism']\n",
    "\n",
    "#Train test split\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, random_state =42, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dylan\\anaconda3.1\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression Model\n",
    "lr2 = LogisticRegression()\n",
    "lr2.fit(X_train2, y_train2)\n",
    "\n",
    "#Storing Accuracy Scores\n",
    "log_train2 = lr2.score(X_train2, y_train2)\n",
    "log_test2 = lr2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest with Hyperparameter tuning\n",
    "rf2= RandomForestClassifier(random_state = 42)\n",
    "rf_params = {\n",
    "    'n_estimators': [120, 130],\n",
    "    'max_depth': [15,20],\n",
    "    'max_features' : [15,20],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "gs1 = GridSearchCV(rf, param_grid= rf_params, cv = 3, n_jobs = -1)\n",
    "\n",
    "gs1.fit(X_train2, y_train2)\n",
    "\n",
    "#Storing Accuracy Scores\n",
    "rf_train2 = gs1.score(X_train2, y_train2)\n",
    "rf_test2 = gs1.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ada Boost with Hyperparam tuning\n",
    "ada= AdaBoostClassifier(base_estimator = DecisionTreeClassifier(random_state = 42))\n",
    "\n",
    "ada_params= {\n",
    "    'n_estimators': [50, 100],\n",
    "    'base_estimator__max_depth':[1,3]\n",
    "}\n",
    "\n",
    "gs2 = GridSearchCV(ada, param_grid = ada_params, cv = 3, n_jobs = -1)\n",
    "gs2.fit(X_train2, y_train2)\n",
    "\n",
    "#Storing Accuracy Scores\n",
    "ada_train2 = gs2.score(X_train2, y_train2)\n",
    "ada_test2 = gs2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graident Boost\n",
    "gboost2= GradientBoostingClassifier(random_state = 42)\n",
    "\n",
    "gboost2.fit(X_train2, y_train2)\n",
    "\n",
    "\n",
    "#Storing Accuracy Scores\n",
    "gboost_train2 = gboost2.score(X_train2, y_train2)\n",
    "gboost_test2 = gboost2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stacked Model\n",
    "level1_estimators = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('gboost', GradientBoostingClassifier())\n",
    "]\n",
    "\n",
    "stacked_model2 = StackingClassifier(estimators=level1_estimators,\n",
    "                                 final_estimator = LogisticRegression())\n",
    "\n",
    "stacked_model2.fit(X_train2, y_train2)\n",
    "\n",
    "#Storing Accuracy Scores\n",
    "stack_train2 = stacked_model2.score(X_train2, y_train2)\n",
    "stack_test2 = stacked_model2.score(X_test2, y_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(141487, 65)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train2)\n",
    "X_test_sc = ss.transform(X_test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate a CNN.\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(84, input_shape = (65,), activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(32, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# Compile it\n",
    "model.compile(loss = 'bce', optimizer = 'adam', metrics = ['accuracy'])\n",
    "\n",
    "# Fit it\n",
    "res = model.fit(X_train_sc, y_train2,\n",
    "                epochs = 10,\n",
    "                batch_size = 32,\n",
    "                validation_data = (X_test_sc, y_test2),\n",
    "                verbose = 0) # No printing of our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5997921824455261"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Save Accuracy Scores\n",
    "train_loss = res.history['accuracy']\n",
    "test_loss = res.history['val_accuracy']\n",
    "\n",
    "neuralnet_train = max(train_loss)\n",
    "neuralnet_test = max(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>diff</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.586831</td>\n",
       "      <td>0.587728</td>\n",
       "      <td>-0.000896</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.588386</td>\n",
       "      <td>0.587070</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.588386</td>\n",
       "      <td>0.587070</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.588386</td>\n",
       "      <td>0.587070</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.588386</td>\n",
       "      <td>0.587070</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>knn</th>\n",
       "      <td>0.534304</td>\n",
       "      <td>0.534614</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        train_scores  test_scores      diff  baseline\n",
       "logreg      0.586831     0.587728 -0.000896      0.58\n",
       "rf          0.588386     0.587070  0.001316      0.58\n",
       "ada         0.588386     0.587070  0.001316      0.58\n",
       "gb          0.588386     0.587070  0.001316      0.58\n",
       "stack       0.588386     0.587070  0.001316      0.58\n",
       "knn         0.534304     0.534614 -0.000310      0.58"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Evaluation No Dummies\n",
    "train_scores = [log_train, rf_train, ada_train, gb_train, stack_train, knn_train]\n",
    "eval_df = pd.DataFrame(train_scores, columns = ['train_scores'])\n",
    "\n",
    "eval_df['test_scores'] = [log_test, rf_test, ada_test, gb_test, stack_test, knn_test]\n",
    "eval_df.index = ['logreg', 'rf', 'ada', 'gb', 'stack', 'knn']\n",
    "eval_df['diff'] = eval_df['train_scores'] - eval_df['test_scores']\n",
    "eval_df['baseline'] = .58\n",
    "\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_scores</th>\n",
       "      <th>test_scores</th>\n",
       "      <th>diff</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>logreg</th>\n",
       "      <td>0.598776</td>\n",
       "      <td>0.599262</td>\n",
       "      <td>-0.000486</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rf</th>\n",
       "      <td>0.603236</td>\n",
       "      <td>0.597714</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.599362</td>\n",
       "      <td>0.599220</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gb</th>\n",
       "      <td>0.598988</td>\n",
       "      <td>0.598711</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stack</th>\n",
       "      <td>0.600981</td>\n",
       "      <td>0.600301</td>\n",
       "      <td>0.000680</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neuralnet</th>\n",
       "      <td>0.598945</td>\n",
       "      <td>0.599792</td>\n",
       "      <td>-0.000847</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           train_scores  test_scores      diff  baseline\n",
       "logreg         0.598776     0.599262 -0.000486      0.58\n",
       "rf             0.603236     0.597714  0.005521      0.58\n",
       "ada            0.599362     0.599220  0.000143      0.58\n",
       "gb             0.598988     0.598711  0.000277      0.58\n",
       "stack          0.600981     0.600301  0.000680      0.58\n",
       "neuralnet      0.598945     0.599792 -0.000847      0.58"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Evaluation With Dummies\n",
    "train_scores2 = [log_train2, rf_train2, ada_train2, gboost_train2, stack_train2, neuralnet_train]\n",
    "eval_df2 = pd.DataFrame(train_scores2, columns = ['train_scores'])\n",
    "\n",
    "eval_df2['test_scores'] = [log_test2, rf_test2, ada_test2, gboost_test2, stack_test2, neuralnet_test]\n",
    "eval_df2.index = ['logreg', 'rf', 'ada', 'gb', 'stack', 'neuralnet']\n",
    "eval_df2['diff'] = eval_df2['train_scores'] - eval_df2['test_scores']\n",
    "eval_df2['baseline'] = .58\n",
    "\n",
    "eval_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 2: Criminal history feature set - Florida**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model 3: Behavioral feature set - Georgia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final selected models for each dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FINAL NOTES**\n",
    "- The model statistics are exported [here](../data/model_stats.csv).\n",
    "- The next notebook in the series is [Results and Recommendations](./04_results.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "5c5d815f4904d5c36e1cb6a23cb867a61c9881b6acdb1b6d63422ceae43ed5d6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
